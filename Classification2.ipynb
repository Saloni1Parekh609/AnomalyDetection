{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv('Random_All.csv')\n",
    "df_2 = pd.read_csv('Random_All_Norm.csv')\n",
    "df_3 = pd.read_csv('SRI_All.csv')\n",
    "df_4 = pd.read_csv('SRI_All_Norm.csv')\n",
    "df_5 = pd.read_csv('Random_Country.csv')\n",
    "df_6 = pd.read_csv('Random_Country_Norm.csv')\n",
    "df_7 = pd.read_csv('SRI_Country.csv')\n",
    "df_8 = pd.read_csv('SRI_Country_Norm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RanARI treatment (% of children under 5 taken to a health provider)</th>\n",
       "      <th>RanAccess to electricity (% of population)</th>\n",
       "      <th>RanAdjusted net national income (annual % growth)</th>\n",
       "      <th>RanAdjusted net national income per capita (annual % growth)</th>\n",
       "      <th>RanAdolescents out of school (% of lower secondary school age)</th>\n",
       "      <th>RanAdults (ages 15+) and children (ages 0-14) newly infected with HIV</th>\n",
       "      <th>RanAdults (ages 15+) newly infected with HIV</th>\n",
       "      <th>RanAir transport, passengers carried</th>\n",
       "      <th>RanBirths attended by skilled health staff (% of total)</th>\n",
       "      <th>RanBorrowers from commercial banks (per 1,000 adults)</th>\n",
       "      <th>...</th>\n",
       "      <th>RanTotal alcohol consumption per capita (liters of pure alcohol, projected estimates, 15+ years of age)</th>\n",
       "      <th>RanTotal debt service (% of GNI)</th>\n",
       "      <th>RanTrade (% of GDP)</th>\n",
       "      <th>RanTravel services (% of commercial service exports)</th>\n",
       "      <th>RanUHC service coverage index</th>\n",
       "      <th>RanUnmet need for contraception (% of married women ages 15-49)</th>\n",
       "      <th>RanUrban population (% of total population)</th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.280608</td>\n",
       "      <td>0.091388</td>\n",
       "      <td>-2.035433</td>\n",
       "      <td>3.320021</td>\n",
       "      <td>-0.179372</td>\n",
       "      <td>-0.183099</td>\n",
       "      <td>-0.155835</td>\n",
       "      <td>0.307420</td>\n",
       "      <td>-8.328502</td>\n",
       "      <td>0.562510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380384</td>\n",
       "      <td>0.405094</td>\n",
       "      <td>0.224774</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.460967</td>\n",
       "      <td>-0.919919</td>\n",
       "      <td>0.933944</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.622162</td>\n",
       "      <td>2.733320</td>\n",
       "      <td>0.669289</td>\n",
       "      <td>1.355332</td>\n",
       "      <td>-0.179372</td>\n",
       "      <td>-0.183099</td>\n",
       "      <td>3.845733</td>\n",
       "      <td>-0.777385</td>\n",
       "      <td>0.106280</td>\n",
       "      <td>-0.318351</td>\n",
       "      <td>...</td>\n",
       "      <td>3.122264</td>\n",
       "      <td>-0.400366</td>\n",
       "      <td>-0.232684</td>\n",
       "      <td>-0.592593</td>\n",
       "      <td>0.972914</td>\n",
       "      <td>-0.917543</td>\n",
       "      <td>1.588362</td>\n",
       "      <td>0</td>\n",
       "      <td>2001</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.038077</td>\n",
       "      <td>0.215125</td>\n",
       "      <td>0.075741</td>\n",
       "      <td>0.209425</td>\n",
       "      <td>-0.179372</td>\n",
       "      <td>-0.183099</td>\n",
       "      <td>4.342282</td>\n",
       "      <td>0.696113</td>\n",
       "      <td>0.019324</td>\n",
       "      <td>1.519854</td>\n",
       "      <td>...</td>\n",
       "      <td>1.099635</td>\n",
       "      <td>-0.429320</td>\n",
       "      <td>0.203743</td>\n",
       "      <td>-1.481481</td>\n",
       "      <td>0.322559</td>\n",
       "      <td>-0.915141</td>\n",
       "      <td>0.086864</td>\n",
       "      <td>0</td>\n",
       "      <td>2002</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.055722</td>\n",
       "      <td>0.940383</td>\n",
       "      <td>1.595019</td>\n",
       "      <td>0.357377</td>\n",
       "      <td>-0.179372</td>\n",
       "      <td>-0.183099</td>\n",
       "      <td>2.755945</td>\n",
       "      <td>-1.024735</td>\n",
       "      <td>-8.144928</td>\n",
       "      <td>0.484245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183283</td>\n",
       "      <td>0.025734</td>\n",
       "      <td>-0.410519</td>\n",
       "      <td>0.036473</td>\n",
       "      <td>0.200669</td>\n",
       "      <td>-0.912738</td>\n",
       "      <td>0.693920</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.028089</td>\n",
       "      <td>-4.366486</td>\n",
       "      <td>0.755514</td>\n",
       "      <td>0.661548</td>\n",
       "      <td>-0.179372</td>\n",
       "      <td>-0.183099</td>\n",
       "      <td>0.887984</td>\n",
       "      <td>0.494700</td>\n",
       "      <td>0.038647</td>\n",
       "      <td>-0.398757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104840</td>\n",
       "      <td>0.707205</td>\n",
       "      <td>-0.615805</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.395417</td>\n",
       "      <td>-0.908900</td>\n",
       "      <td>-0.334103</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RanARI treatment (% of children under 5 taken to a health provider)  \\\n",
       "0                                          -2.280608                     \n",
       "1                                          -2.622162                     \n",
       "2                                           0.038077                     \n",
       "3                                          -0.055722                     \n",
       "4                                           0.028089                     \n",
       "\n",
       "   RanAccess to electricity (% of population)  \\\n",
       "0                                    0.091388   \n",
       "1                                    2.733320   \n",
       "2                                    0.215125   \n",
       "3                                    0.940383   \n",
       "4                                   -4.366486   \n",
       "\n",
       "   RanAdjusted net national income (annual % growth)  \\\n",
       "0                                          -2.035433   \n",
       "1                                           0.669289   \n",
       "2                                           0.075741   \n",
       "3                                           1.595019   \n",
       "4                                           0.755514   \n",
       "\n",
       "   RanAdjusted net national income per capita (annual % growth)  \\\n",
       "0                                           3.320021              \n",
       "1                                           1.355332              \n",
       "2                                           0.209425              \n",
       "3                                           0.357377              \n",
       "4                                           0.661548              \n",
       "\n",
       "   RanAdolescents out of school (% of lower secondary school age)  \\\n",
       "0                                          -0.179372                \n",
       "1                                          -0.179372                \n",
       "2                                          -0.179372                \n",
       "3                                          -0.179372                \n",
       "4                                          -0.179372                \n",
       "\n",
       "   RanAdults (ages 15+) and children (ages 0-14) newly infected with HIV  \\\n",
       "0                                          -0.183099                       \n",
       "1                                          -0.183099                       \n",
       "2                                          -0.183099                       \n",
       "3                                          -0.183099                       \n",
       "4                                          -0.183099                       \n",
       "\n",
       "   RanAdults (ages 15+) newly infected with HIV  \\\n",
       "0                                     -0.155835   \n",
       "1                                      3.845733   \n",
       "2                                      4.342282   \n",
       "3                                      2.755945   \n",
       "4                                      0.887984   \n",
       "\n",
       "   RanAir transport, passengers carried  \\\n",
       "0                              0.307420   \n",
       "1                             -0.777385   \n",
       "2                              0.696113   \n",
       "3                             -1.024735   \n",
       "4                              0.494700   \n",
       "\n",
       "   RanBirths attended by skilled health staff (% of total)  \\\n",
       "0                                          -8.328502         \n",
       "1                                           0.106280         \n",
       "2                                           0.019324         \n",
       "3                                          -8.144928         \n",
       "4                                           0.038647         \n",
       "\n",
       "   RanBorrowers from commercial banks (per 1,000 adults)  ...  \\\n",
       "0                                           0.562510      ...   \n",
       "1                                          -0.318351      ...   \n",
       "2                                           1.519854      ...   \n",
       "3                                           0.484245      ...   \n",
       "4                                          -0.398757      ...   \n",
       "\n",
       "   RanTotal alcohol consumption per capita (liters of pure alcohol, projected estimates, 15+ years of age)  \\\n",
       "0                                           0.380384                                                         \n",
       "1                                           3.122264                                                         \n",
       "2                                           1.099635                                                         \n",
       "3                                           0.183283                                                         \n",
       "4                                           0.104840                                                         \n",
       "\n",
       "   RanTotal debt service (% of GNI)  RanTrade (% of GDP)  \\\n",
       "0                          0.405094             0.224774   \n",
       "1                         -0.400366            -0.232684   \n",
       "2                         -0.429320             0.203743   \n",
       "3                          0.025734            -0.410519   \n",
       "4                          0.707205            -0.615805   \n",
       "\n",
       "   RanTravel services (% of commercial service exports)  \\\n",
       "0                                           0.074074      \n",
       "1                                          -0.592593      \n",
       "2                                          -1.481481      \n",
       "3                                           0.036473      \n",
       "4                                           0.037037      \n",
       "\n",
       "   RanUHC service coverage index  \\\n",
       "0                       0.460967   \n",
       "1                       0.972914   \n",
       "2                       0.322559   \n",
       "3                       0.200669   \n",
       "4                       0.395417   \n",
       "\n",
       "   RanUnmet need for contraception (% of married women ages 15-49)  \\\n",
       "0                                          -0.919919                 \n",
       "1                                          -0.917543                 \n",
       "2                                          -0.915141                 \n",
       "3                                          -0.912738                 \n",
       "4                                          -0.908900                 \n",
       "\n",
       "   RanUrban population (% of total population)  Country Name  Year  Label  \n",
       "0                                     0.933944             0  2000    1.0  \n",
       "1                                     1.588362             0  2001    1.0  \n",
       "2                                     0.086864             0  2002    1.0  \n",
       "3                                     0.693920             0  2003    1.0  \n",
       "4                                    -0.334103             0  2004    0.0  \n",
       "\n",
       "[5 rows x 139 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_7.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "df_7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_test, predicted_test):\n",
    "    print ('Accuracy:', accuracy_score(y_test, predicted_test))\n",
    "    print ('F1 score:', f1_score(y_test, predicted_test,average='weighted'))\n",
    "    print ('Recall:', recall_score(y_test, predicted_test,average='weighted'))\n",
    "    print ('Precision:', precision_score(y_test, predicted_test,average='weighted'))\n",
    "    print ('\\n Classification Report:\\n', classification_report(y_test, predicted_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. GaussianNB</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RanARI treatment (% of children under 5 taken to a health provider)</th>\n",
       "      <th>RanAccess to electricity (% of population)</th>\n",
       "      <th>RanAdjusted net national income (annual % growth)</th>\n",
       "      <th>RanAdjusted net national income per capita (annual % growth)</th>\n",
       "      <th>RanAdolescents out of school (% of lower secondary school age)</th>\n",
       "      <th>RanAdults (ages 15+) and children (ages 0-14) newly infected with HIV</th>\n",
       "      <th>RanAdults (ages 15+) newly infected with HIV</th>\n",
       "      <th>RanAir transport, passengers carried</th>\n",
       "      <th>RanBirths attended by skilled health staff (% of total)</th>\n",
       "      <th>RanBorrowers from commercial banks (per 1,000 adults)</th>\n",
       "      <th>...</th>\n",
       "      <th>RanTotal alcohol consumption per capita (liters of pure alcohol, projected estimates, 15+ years of age)</th>\n",
       "      <th>RanTotal debt service (% of GNI)</th>\n",
       "      <th>RanTrade (% of GDP)</th>\n",
       "      <th>RanTravel services (% of commercial service exports)</th>\n",
       "      <th>RanUHC service coverage index</th>\n",
       "      <th>RanUnmet need for contraception (% of married women ages 15-49)</th>\n",
       "      <th>RanUrban population (% of total population)</th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.007164</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>-0.006394</td>\n",
       "      <td>0.010429</td>\n",
       "      <td>-0.000563</td>\n",
       "      <td>-0.000575</td>\n",
       "      <td>-0.000490</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>-0.026163</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.001448</td>\n",
       "      <td>-0.002890</td>\n",
       "      <td>0.002934</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.007958</td>\n",
       "      <td>0.008296</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>0.004113</td>\n",
       "      <td>-0.000544</td>\n",
       "      <td>-0.000556</td>\n",
       "      <td>0.011672</td>\n",
       "      <td>-0.002359</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>-0.000966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009476</td>\n",
       "      <td>-0.001215</td>\n",
       "      <td>-0.000706</td>\n",
       "      <td>-0.001799</td>\n",
       "      <td>0.002953</td>\n",
       "      <td>-0.002785</td>\n",
       "      <td>0.004821</td>\n",
       "      <td>0</td>\n",
       "      <td>2001</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>-0.000826</td>\n",
       "      <td>-0.000843</td>\n",
       "      <td>0.019999</td>\n",
       "      <td>0.003206</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005065</td>\n",
       "      <td>-0.001977</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>-0.006823</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>-0.004215</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0</td>\n",
       "      <td>2002</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000297</td>\n",
       "      <td>0.005006</td>\n",
       "      <td>0.008491</td>\n",
       "      <td>0.001902</td>\n",
       "      <td>-0.000955</td>\n",
       "      <td>-0.000975</td>\n",
       "      <td>0.014671</td>\n",
       "      <td>-0.005455</td>\n",
       "      <td>-0.043359</td>\n",
       "      <td>0.002578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>-0.002185</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>-0.004859</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000135</td>\n",
       "      <td>-0.020921</td>\n",
       "      <td>0.003620</td>\n",
       "      <td>0.003170</td>\n",
       "      <td>-0.000859</td>\n",
       "      <td>-0.000877</td>\n",
       "      <td>0.004254</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>-0.001911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.003388</td>\n",
       "      <td>-0.002950</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.001895</td>\n",
       "      <td>-0.004355</td>\n",
       "      <td>-0.001601</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RanARI treatment (% of children under 5 taken to a health provider)  \\\n",
       "0                                          -0.007164                     \n",
       "1                                          -0.007958                     \n",
       "2                                           0.000175                     \n",
       "3                                          -0.000297                     \n",
       "4                                           0.000135                     \n",
       "\n",
       "   RanAccess to electricity (% of population)  \\\n",
       "0                                    0.000287   \n",
       "1                                    0.008296   \n",
       "2                                    0.000991   \n",
       "3                                    0.005006   \n",
       "4                                   -0.020921   \n",
       "\n",
       "   RanAdjusted net national income (annual % growth)  \\\n",
       "0                                          -0.006394   \n",
       "1                                           0.002031   \n",
       "2                                           0.000349   \n",
       "3                                           0.008491   \n",
       "4                                           0.003620   \n",
       "\n",
       "   RanAdjusted net national income per capita (annual % growth)  \\\n",
       "0                                           0.010429              \n",
       "1                                           0.004113              \n",
       "2                                           0.000965              \n",
       "3                                           0.001902              \n",
       "4                                           0.003170              \n",
       "\n",
       "   RanAdolescents out of school (% of lower secondary school age)  \\\n",
       "0                                          -0.000563                \n",
       "1                                          -0.000544                \n",
       "2                                          -0.000826                \n",
       "3                                          -0.000955                \n",
       "4                                          -0.000859                \n",
       "\n",
       "   RanAdults (ages 15+) and children (ages 0-14) newly infected with HIV  \\\n",
       "0                                          -0.000575                       \n",
       "1                                          -0.000556                       \n",
       "2                                          -0.000843                       \n",
       "3                                          -0.000975                       \n",
       "4                                          -0.000877                       \n",
       "\n",
       "   RanAdults (ages 15+) newly infected with HIV  \\\n",
       "0                                     -0.000490   \n",
       "1                                      0.011672   \n",
       "2                                      0.019999   \n",
       "3                                      0.014671   \n",
       "4                                      0.004254   \n",
       "\n",
       "   RanAir transport, passengers carried  \\\n",
       "0                              0.000966   \n",
       "1                             -0.002359   \n",
       "2                              0.003206   \n",
       "3                             -0.005455   \n",
       "4                              0.002370   \n",
       "\n",
       "   RanBirths attended by skilled health staff (% of total)  \\\n",
       "0                                          -0.026163         \n",
       "1                                           0.000323         \n",
       "2                                           0.000089         \n",
       "3                                          -0.043359         \n",
       "4                                           0.000185         \n",
       "\n",
       "   RanBorrowers from commercial banks (per 1,000 adults)  ...  \\\n",
       "0                                           0.001767      ...   \n",
       "1                                          -0.000966      ...   \n",
       "2                                           0.007000      ...   \n",
       "3                                           0.002578      ...   \n",
       "4                                          -0.001911      ...   \n",
       "\n",
       "   RanTotal alcohol consumption per capita (liters of pure alcohol, projected estimates, 15+ years of age)  \\\n",
       "0                                           0.001195                                                         \n",
       "1                                           0.009476                                                         \n",
       "2                                           0.005065                                                         \n",
       "3                                           0.000976                                                         \n",
       "4                                           0.000502                                                         \n",
       "\n",
       "   RanTotal debt service (% of GNI)  RanTrade (% of GDP)  \\\n",
       "0                          0.001273             0.000706   \n",
       "1                         -0.001215            -0.000706   \n",
       "2                         -0.001977             0.000938   \n",
       "3                          0.000137            -0.002185   \n",
       "4                          0.003388            -0.002950   \n",
       "\n",
       "   RanTravel services (% of commercial service exports)  \\\n",
       "0                                           0.000233      \n",
       "1                                          -0.001799      \n",
       "2                                          -0.006823      \n",
       "3                                           0.000194      \n",
       "4                                           0.000177      \n",
       "\n",
       "   RanUHC service coverage index  \\\n",
       "0                       0.001448   \n",
       "1                       0.002953   \n",
       "2                       0.001486   \n",
       "3                       0.001068   \n",
       "4                       0.001895   \n",
       "\n",
       "   RanUnmet need for contraception (% of married women ages 15-49)  \\\n",
       "0                                          -0.002890                 \n",
       "1                                          -0.002785                 \n",
       "2                                          -0.004215                 \n",
       "3                                          -0.004859                 \n",
       "4                                          -0.004355                 \n",
       "\n",
       "   RanUrban population (% of total population)  Country Name  Year  Label  \n",
       "0                                     0.002934             0  2000    1.0  \n",
       "1                                     0.004821             0  2001    1.0  \n",
       "2                                     0.000400             0  2002    1.0  \n",
       "3                                     0.003694             0  2003    1.0  \n",
       "4                                    -0.001601             0  2004    0.0  \n",
       "\n",
       "[5 rows x 139 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_8.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "df_8.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6619519094766619\n",
      "F1 score: 0.6541657505615185\n",
      "Recall: 0.6619519094766619\n",
      "Precision: 0.686408381856462\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.82      0.70       683\n",
      "         1.0       0.76      0.51      0.61       731\n",
      "\n",
      "    accuracy                           0.66      1414\n",
      "   macro avg       0.68      0.67      0.66      1414\n",
      "weighted avg       0.69      0.66      0.65      1414\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_1.iloc[:, :-1]\n",
    "y = df_1['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6739288307915758\n",
      "F1 score: 0.6730117697143908\n",
      "Recall: 0.6739288307915758\n",
      "Precision: 0.6745846813381164\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.62      0.65       673\n",
      "         1.0       0.67      0.72      0.69       704\n",
      "\n",
      "    accuracy                           0.67      1377\n",
      "   macro avg       0.67      0.67      0.67      1377\n",
      "weighted avg       0.67      0.67      0.67      1377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_2.iloc[:, :-1]\n",
    "y = df_2['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6225212464589235\n",
      "F1 score: 0.5993560515221521\n",
      "Recall: 0.6225212464589235\n",
      "Precision: 0.6809590211225803\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.88      0.69       672\n",
      "         1.0       0.79      0.39      0.52       740\n",
      "\n",
      "    accuracy                           0.62      1412\n",
      "   macro avg       0.68      0.63      0.60      1412\n",
      "weighted avg       0.68      0.62      0.60      1412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_3.iloc[:, :-1]\n",
    "y = df_3['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6475290697674418\n",
      "F1 score: 0.6457687422338078\n",
      "Recall: 0.6475290697674418\n",
      "Precision: 0.6505210859279856\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.58      0.62       688\n",
      "         1.0       0.63      0.72      0.67       688\n",
      "\n",
      "    accuracy                           0.65      1376\n",
      "   macro avg       0.65      0.65      0.65      1376\n",
      "weighted avg       0.65      0.65      0.65      1376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_4.iloc[:, :-1]\n",
    "y = df_4['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6409893992932862\n",
      "F1 score: 0.6325563187508428\n",
      "Recall: 0.6409893992932862\n",
      "Precision: 0.6511059666587057\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.79      0.69       722\n",
      "         1.0       0.69      0.49      0.57       693\n",
      "\n",
      "    accuracy                           0.64      1415\n",
      "   macro avg       0.65      0.64      0.63      1415\n",
      "weighted avg       0.65      0.64      0.63      1415\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_5.iloc[:, :-1]\n",
    "y = df_5['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6944847605224964\n",
      "F1 score: 0.692453719795246\n",
      "Recall: 0.6944847605224964\n",
      "Precision: 0.6974195837510723\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.62      0.66       673\n",
      "         1.0       0.68      0.77      0.72       705\n",
      "\n",
      "    accuracy                           0.69      1378\n",
      "   macro avg       0.70      0.69      0.69      1378\n",
      "weighted avg       0.70      0.69      0.69      1378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_6.iloc[:, :-1]\n",
    "y = df_6['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6090014064697609\n",
      "F1 score: 0.5751539128267914\n",
      "Recall: 0.6090014064697609\n",
      "Precision: 0.6563412397888957\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.89      0.70       716\n",
      "         1.0       0.74      0.33      0.45       706\n",
      "\n",
      "    accuracy                           0.61      1422\n",
      "   macro avg       0.66      0.61      0.57      1422\n",
      "weighted avg       0.66      0.61      0.58      1422\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_7.iloc[:, :-1]\n",
    "y = df_7['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6331877729257642\n",
      "F1 score: 0.6304531029161154\n",
      "Recall: 0.6331877729257642\n",
      "Precision: 0.6411375129325235\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.54      0.60       707\n",
      "         1.0       0.60      0.73      0.66       667\n",
      "\n",
      "    accuracy                           0.63      1374\n",
      "   macro avg       0.64      0.64      0.63      1374\n",
      "weighted avg       0.64      0.63      0.63      1374\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_8.iloc[:, :-1]\n",
    "y = df_8['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>RandomizedSearchCV</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:282: UserWarning: The total space of parameters 24 is smaller than n_iter=100. Running 24 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9404677533664068\n",
      "F1 score: 0.9404751154407025\n",
      "Recall: 0.9404677533664068\n",
      "Precision: 0.9405165063133826\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.94      0.94       729\n",
      "         1.0       0.93      0.94      0.94       682\n",
      "\n",
      "    accuracy                           0.94      1411\n",
      "   macro avg       0.94      0.94      0.94      1411\n",
      "weighted avg       0.94      0.94      0.94      1411\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [100, 120, 150, 160, 170, 180]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "#max_depth = [10, 20, 30]\n",
    "#max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "#min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "#min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               #'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "               #'max_depth': max_depth}\n",
    "\n",
    "#               'min_samples_split': min_samples_split,\n",
    "\n",
    "\n",
    "rnd1 = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rnd1, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "X = df_1.iloc[:, :-1]\n",
    "y = df_1['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_random.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:282: UserWarning: The total space of parameters 24 is smaller than n_iter=100. Running 24 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   56.1s\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8504672897196262\n",
      "F1 score: 0.8180289769074814\n",
      "Recall: 0.8504672897196262\n",
      "Precision: 0.8342802810695484\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.98      0.92       706\n",
      "         1.0       0.72      0.24      0.36       150\n",
      "\n",
      "    accuracy                           0.85       856\n",
      "   macro avg       0.79      0.61      0.64       856\n",
      "weighted avg       0.83      0.85      0.82       856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [100, 120, 150, 160, 170, 180]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "#max_depth = [10, 20, 30]\n",
    "#max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "#min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "#min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               #'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "               #'max_depth': max_depth}\n",
    "\n",
    "#               'min_samples_split': min_samples_split,\n",
    "\n",
    "\n",
    "rnd1 = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rnd1, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "X = df_1.iloc[:, :-1]\n",
    "y = df_1['Label']\n",
    "\n",
    "#smt = SMOTETomek(sampling_strategy='all')\n",
    "#X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_random.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 180, 'max_features': 'sqrt', 'bootstrap': False}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:282: UserWarning: The total space of parameters 12 is smaller than n_iter=100. Running 12 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9428772919605077\n",
      "F1 score: 0.942880559858112\n",
      "Recall: 0.9428772919605077\n",
      "Precision: 0.9429072770816017\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.94      0.94       723\n",
      "         1.0       0.94      0.95      0.94       695\n",
      "\n",
      "    accuracy                           0.94      1418\n",
      "   macro avg       0.94      0.94      0.94      1418\n",
      "weighted avg       0.94      0.94      0.94      1418\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [100, 120, 150, 160, 170, 180]\n",
    "# Number of features to consider at every split\n",
    "#max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "#max_depth = [10, 20, 30]\n",
    "#max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "#min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "#min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               #'max_features': max_features,\n",
    "               #'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "               #'max_depth': max_depth}\n",
    "\n",
    "#               'min_samples_split': min_samples_split,\n",
    "\n",
    "\n",
    "rnd1 = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rnd1, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "X = df_7.iloc[:, :-1]\n",
    "y = df_7['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_random.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:282: UserWarning: The total space of parameters 12 is smaller than n_iter=100. Running 12 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8813953488372093\n",
      "F1 score: 0.8660762528437814\n",
      "Recall: 0.8813953488372093\n",
      "Precision: 0.8643716879873089\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.97      0.93       741\n",
      "         1.0       0.63      0.34      0.45       119\n",
      "\n",
      "    accuracy                           0.88       860\n",
      "   macro avg       0.77      0.66      0.69       860\n",
      "weighted avg       0.86      0.88      0.87       860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [100, 120, 150, 160, 170, 180]\n",
    "# Number of features to consider at every split\n",
    "#max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "#max_depth = [10, 20, 30]\n",
    "#max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "#min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "#min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               #'max_features': max_features,\n",
    "               #'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "               #'max_depth': max_depth}\n",
    "\n",
    "#               'min_samples_split': min_samples_split,\n",
    "\n",
    "\n",
    "rnd1 = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rnd1, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "X = df_7.iloc[:, :-1]\n",
    "y = df_7['Label']\n",
    "\n",
    "#smt = SMOTETomek(sampling_strategy='all')\n",
    "#X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_random.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 160, 'bootstrap': False}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_7_drop = df_7.drop(df_7[df_7['Year'] == 2013].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:282: UserWarning: The total space of parameters 12 is smaller than n_iter=100. Running 12 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8465116279069768\n",
      "F1 score: 0.8294020167945896\n",
      "Recall: 0.8465116279069768\n",
      "Precision: 0.8252423194163784\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.95      0.91       179\n",
      "         1.0       0.57      0.33      0.42        36\n",
      "\n",
      "    accuracy                           0.85       215\n",
      "   macro avg       0.72      0.64      0.67       215\n",
      "weighted avg       0.83      0.85      0.83       215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [100, 120, 150, 160, 170, 180]\n",
    "# Number of features to consider at every split\n",
    "#max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "#max_depth = [10, 20, 30]\n",
    "#max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "#min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "#min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               #'max_features': max_features,\n",
    "               #'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "               #'max_depth': max_depth}\n",
    "\n",
    "#               'min_samples_split': min_samples_split,\n",
    "\n",
    "\n",
    "rnd1 = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rnd1, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "X = df_7.iloc[:, :-1]\n",
    "y = df_7['Label']\n",
    "\n",
    "#df_7_drop = X.drop(X[X['Year'] == 2003].index)\n",
    "X_train = df_7_drop.iloc[:, :-1]\n",
    "y_train = df_7_drop['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X_train, y_train)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "\n",
    "rf_random.fit(X_smt, y_smt)\n",
    "\n",
    "df_2003 = df_7[df_7['Year'] == 2013]\n",
    "X_test = df_2003.iloc[:, :-1]\n",
    "y_test = df_2003['Label']\n",
    "\n",
    "y_pred = rf_random.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country Name  Label\n",
       "0             0    0.0\n",
       "1             0    0.0\n",
       "2             5    0.0\n",
       "3            10    0.0\n",
       "4            15    0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = pd.DataFrame()\n",
    "predicted['Country Name'] = list(X_test['Country Name'])\n",
    "predicted['Label'] = y_pred\n",
    "predicted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Angola</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Australia</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country Name  Label\n",
       "0  Afghanistan    0.0\n",
       "1  Afghanistan    0.0\n",
       "2       Angola    0.0\n",
       "3    Australia    0.0\n",
       "4   Bangladesh    0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldmap_pred = predicted[(predicted['Label'] == 1.0)]\n",
    "worldmap_pred.to_csv('WorldmapPred_2013.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>ARI treatment (% of children under 5 taken to a health provider)</th>\n",
       "      <th>Access to electricity (% of population)</th>\n",
       "      <th>Adjusted net national income (annual % growth)</th>\n",
       "      <th>Adjusted net national income per capita (annual % growth)</th>\n",
       "      <th>Adolescents out of school (% of lower secondary school age)</th>\n",
       "      <th>Adults (ages 15+) and children (ages 0-14) newly infected with HIV</th>\n",
       "      <th>...</th>\n",
       "      <th>Suicide mortality rate (per 100,000 population)</th>\n",
       "      <th>Time required to build a warehouse (days)</th>\n",
       "      <th>Total alcohol consumption per capita (liters of pure alcohol, projected estimates, 15+ years of age)</th>\n",
       "      <th>Total debt service (% of GNI)</th>\n",
       "      <th>Trade (% of GDP)</th>\n",
       "      <th>Travel services (% of commercial service exports)</th>\n",
       "      <th>UHC service coverage index</th>\n",
       "      <th>Unmet need for contraception (% of married women ages 15-49)</th>\n",
       "      <th>Urban population (% of total population)</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1970</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>...</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>0</td>\n",
       "      <td>21.7281100678648</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>11.642999999999999</td>\n",
       "      <td>..</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1971</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>...</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0631374536424</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>12.020999999999999</td>\n",
       "      <td>..</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1972</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>...</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>0</td>\n",
       "      <td>32.8690810352185</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>12.41</td>\n",
       "      <td>..</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1973</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>...</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>0</td>\n",
       "      <td>27.6923087928995</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>12.809000000000001</td>\n",
       "      <td>..</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1974</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>80.27309</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>...</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>0</td>\n",
       "      <td>28.8659801551706</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>13.219000000000001</td>\n",
       "      <td>..</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 146 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index Country Name  Year  \\\n",
       "0           0     10  Afghanistan  1970   \n",
       "1           1     11  Afghanistan  1971   \n",
       "2           2     12  Afghanistan  1972   \n",
       "3           3     13  Afghanistan  1973   \n",
       "4           4     14  Afghanistan  1974   \n",
       "\n",
       "  ARI treatment (% of children under 5 taken to a health provider)  \\\n",
       "0                                                 ..                 \n",
       "1                                                 ..                 \n",
       "2                                                 ..                 \n",
       "3                                                 ..                 \n",
       "4                                                 ..                 \n",
       "\n",
       "  Access to electricity (% of population)  \\\n",
       "0                                      ..   \n",
       "1                                      ..   \n",
       "2                                      ..   \n",
       "3                                      ..   \n",
       "4                                      ..   \n",
       "\n",
       "  Adjusted net national income (annual % growth)  \\\n",
       "0                                             ..   \n",
       "1                                             ..   \n",
       "2                                             ..   \n",
       "3                                             ..   \n",
       "4                                             ..   \n",
       "\n",
       "  Adjusted net national income per capita (annual % growth)  \\\n",
       "0                                                 ..          \n",
       "1                                                 ..          \n",
       "2                                                 ..          \n",
       "3                                                 ..          \n",
       "4                                           80.27309          \n",
       "\n",
       "  Adolescents out of school (% of lower secondary school age)  \\\n",
       "0                                                 ..            \n",
       "1                                                 ..            \n",
       "2                                                 ..            \n",
       "3                                                 ..            \n",
       "4                                                 ..            \n",
       "\n",
       "  Adults (ages 15+) and children (ages 0-14) newly infected with HIV  ...  \\\n",
       "0                                                 ..                  ...   \n",
       "1                                                 ..                  ...   \n",
       "2                                                 ..                  ...   \n",
       "3                                                 ..                  ...   \n",
       "4                                                 ..                  ...   \n",
       "\n",
       "  Suicide mortality rate (per 100,000 population)  \\\n",
       "0                                              ..   \n",
       "1                                              ..   \n",
       "2                                              ..   \n",
       "3                                              ..   \n",
       "4                                              ..   \n",
       "\n",
       "  Time required to build a warehouse (days)  \\\n",
       "0                                        ..   \n",
       "1                                        ..   \n",
       "2                                        ..   \n",
       "3                                        ..   \n",
       "4                                        ..   \n",
       "\n",
       "  Total alcohol consumption per capita (liters of pure alcohol, projected estimates, 15+ years of age)  \\\n",
       "0                                                  0                                                     \n",
       "1                                                  0                                                     \n",
       "2                                                  0                                                     \n",
       "3                                                  0                                                     \n",
       "4                                                  0                                                     \n",
       "\n",
       "  Total debt service (% of GNI) Trade (% of GDP)  \\\n",
       "0              21.7281100678648               ..   \n",
       "1              27.0631374536424               ..   \n",
       "2              32.8690810352185               ..   \n",
       "3              27.6923087928995               ..   \n",
       "4              28.8659801551706               ..   \n",
       "\n",
       "  Travel services (% of commercial service exports)  \\\n",
       "0                                                ..   \n",
       "1                                                ..   \n",
       "2                                                ..   \n",
       "3                                                ..   \n",
       "4                                                ..   \n",
       "\n",
       "  UHC service coverage index  \\\n",
       "0                         ..   \n",
       "1                         ..   \n",
       "2                         ..   \n",
       "3                         ..   \n",
       "4                         ..   \n",
       "\n",
       "  Unmet need for contraception (% of married women ages 15-49)  \\\n",
       "0                                 11.642999999999999             \n",
       "1                                 12.020999999999999             \n",
       "2                                              12.41             \n",
       "3                                 12.809000000000001             \n",
       "4                                 13.219000000000001             \n",
       "\n",
       "  Urban population (% of total population) Label  \n",
       "0                                       ..   0.0  \n",
       "1                                       ..   0.0  \n",
       "2                                       ..   0.0  \n",
       "3                                       ..   0.0  \n",
       "4                                       ..   0.0  \n",
       "\n",
       "[5 rows x 146 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = pd.read_csv('AnomalyDetection.csv')\n",
    "tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tr['Country Name'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tr['Country Name'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', predicted.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "c = le.fit_transform(c)\n",
    "#df_random.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   5,  10,  15,  21,  25,  28,  32,  37,  41,  45,  50,  55,\n",
       "        59,  64,  69,  75,  81,   1,   6,  11,  16,  22,  26,  29,  33,\n",
       "        38,  42,  46,  51,  56,  60,  65,  70,  76,  82,   2,   7,  12,\n",
       "        17,  23,  27,  30,  34,  39,  43,  47,  52,  57,  61,  66,  77,\n",
       "        83,   3,   8,  13,  18,  24,  31,  35,  40,  48,  53,  62,  67,\n",
       "        71,  78,  84,   4,   9,  19,  36,  49,  54,  58,  63,  68,  72,\n",
       "        79,  14,  20,  44,  73,  80,  74,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198, 199, 200, 201, 202, 203])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(predicted.shape[0]):\n",
    "predicted['Country Name'] = le.inverse_transform(predicted['Country Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Afghanistan',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Angola',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Australia',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bangladesh',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Bermuda',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Botswana',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Brunei Darussalam',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Cabo Verde',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'Central African Republic',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'China',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Costa Rica',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Cyprus',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Dominican Republic',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Equatorial Guinea',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Faroe Islands',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Greece',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Guinea-Bissau',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Albania',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " 'Antigua and Barbuda',\n",
       " ...]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        5\n",
       "3       10\n",
       "4       15\n",
       "      ... \n",
       "210    199\n",
       "211    200\n",
       "212    201\n",
       "213    202\n",
       "214    203\n",
       "Name: Country Name, Length: 215, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted['Country Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = y_pred.tolist()\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>RanARI treatment (% of children under 5 taken to a health provider)</th>\n",
       "      <th>RanAccess to electricity (% of population)</th>\n",
       "      <th>RanAdjusted net national income (annual % growth)</th>\n",
       "      <th>RanAdjusted net national income per capita (annual % growth)</th>\n",
       "      <th>RanAdolescents out of school (% of lower secondary school age)</th>\n",
       "      <th>RanAdults (ages 15+) and children (ages 0-14) newly infected with HIV</th>\n",
       "      <th>RanAdults (ages 15+) newly infected with HIV</th>\n",
       "      <th>RanAir transport, passengers carried</th>\n",
       "      <th>RanBirths attended by skilled health staff (% of total)</th>\n",
       "      <th>...</th>\n",
       "      <th>RanTime required to build a warehouse (days)</th>\n",
       "      <th>RanTotal alcohol consumption per capita (liters of pure alcohol, projected estimates, 15+ years of age)</th>\n",
       "      <th>RanTotal debt service (% of GNI)</th>\n",
       "      <th>RanTrade (% of GDP)</th>\n",
       "      <th>RanTravel services (% of commercial service exports)</th>\n",
       "      <th>RanUHC service coverage index</th>\n",
       "      <th>RanUnmet need for contraception (% of married women ages 15-49)</th>\n",
       "      <th>RanUrban population (% of total population)</th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.055722</td>\n",
       "      <td>0.940383</td>\n",
       "      <td>1.595019</td>\n",
       "      <td>0.357377</td>\n",
       "      <td>-0.179372</td>\n",
       "      <td>-0.183099</td>\n",
       "      <td>2.755945</td>\n",
       "      <td>-1.024735</td>\n",
       "      <td>-8.144928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267800</td>\n",
       "      <td>0.183283</td>\n",
       "      <td>0.025734</td>\n",
       "      <td>-0.410519</td>\n",
       "      <td>0.036473</td>\n",
       "      <td>0.200669</td>\n",
       "      <td>-0.912738</td>\n",
       "      <td>0.693920</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>0.029556</td>\n",
       "      <td>-0.778912</td>\n",
       "      <td>0.156871</td>\n",
       "      <td>-0.270031</td>\n",
       "      <td>-0.179372</td>\n",
       "      <td>-0.183099</td>\n",
       "      <td>0.867859</td>\n",
       "      <td>0.236749</td>\n",
       "      <td>-8.144928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236322</td>\n",
       "      <td>0.496831</td>\n",
       "      <td>-0.206206</td>\n",
       "      <td>0.252292</td>\n",
       "      <td>-0.592593</td>\n",
       "      <td>0.432318</td>\n",
       "      <td>-0.912738</td>\n",
       "      <td>-1.038138</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>23</td>\n",
       "      <td>-2.093040</td>\n",
       "      <td>2.473914</td>\n",
       "      <td>2.013446</td>\n",
       "      <td>0.807887</td>\n",
       "      <td>2.421525</td>\n",
       "      <td>2.704225</td>\n",
       "      <td>-0.150461</td>\n",
       "      <td>-0.706714</td>\n",
       "      <td>-0.009662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.828286</td>\n",
       "      <td>1.469515</td>\n",
       "      <td>0.468565</td>\n",
       "      <td>-0.414294</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.783168</td>\n",
       "      <td>-0.095624</td>\n",
       "      <td>0.894716</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>43</td>\n",
       "      <td>0.038077</td>\n",
       "      <td>-0.031358</td>\n",
       "      <td>-0.023564</td>\n",
       "      <td>0.255371</td>\n",
       "      <td>-0.111211</td>\n",
       "      <td>-0.129577</td>\n",
       "      <td>4.408828</td>\n",
       "      <td>-1.272085</td>\n",
       "      <td>0.067633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.839712</td>\n",
       "      <td>2.298701</td>\n",
       "      <td>-0.774922</td>\n",
       "      <td>0.340398</td>\n",
       "      <td>-1.148148</td>\n",
       "      <td>-0.314381</td>\n",
       "      <td>0.705979</td>\n",
       "      <td>0.238265</td>\n",
       "      <td>10</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>63</td>\n",
       "      <td>-1.685918</td>\n",
       "      <td>0.063474</td>\n",
       "      <td>-0.016307</td>\n",
       "      <td>0.395359</td>\n",
       "      <td>-0.141704</td>\n",
       "      <td>-0.149296</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>-1.091873</td>\n",
       "      <td>-8.183575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>-0.426049</td>\n",
       "      <td>-1.022001</td>\n",
       "      <td>-0.739529</td>\n",
       "      <td>0.531565</td>\n",
       "      <td>-0.548495</td>\n",
       "      <td>-0.832416</td>\n",
       "      <td>-0.169141</td>\n",
       "      <td>15</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  \\\n",
       "3            3   \n",
       "23           3   \n",
       "43          23   \n",
       "63          43   \n",
       "83          63   \n",
       "\n",
       "    RanARI treatment (% of children under 5 taken to a health provider)  \\\n",
       "3                                           -0.055722                     \n",
       "23                                           0.029556                     \n",
       "43                                          -2.093040                     \n",
       "63                                           0.038077                     \n",
       "83                                          -1.685918                     \n",
       "\n",
       "    RanAccess to electricity (% of population)  \\\n",
       "3                                     0.940383   \n",
       "23                                   -0.778912   \n",
       "43                                    2.473914   \n",
       "63                                   -0.031358   \n",
       "83                                    0.063474   \n",
       "\n",
       "    RanAdjusted net national income (annual % growth)  \\\n",
       "3                                            1.595019   \n",
       "23                                           0.156871   \n",
       "43                                           2.013446   \n",
       "63                                          -0.023564   \n",
       "83                                          -0.016307   \n",
       "\n",
       "    RanAdjusted net national income per capita (annual % growth)  \\\n",
       "3                                            0.357377              \n",
       "23                                          -0.270031              \n",
       "43                                           0.807887              \n",
       "63                                           0.255371              \n",
       "83                                           0.395359              \n",
       "\n",
       "    RanAdolescents out of school (% of lower secondary school age)  \\\n",
       "3                                           -0.179372                \n",
       "23                                          -0.179372                \n",
       "43                                           2.421525                \n",
       "63                                          -0.111211                \n",
       "83                                          -0.141704                \n",
       "\n",
       "    RanAdults (ages 15+) and children (ages 0-14) newly infected with HIV  \\\n",
       "3                                           -0.183099                       \n",
       "23                                          -0.183099                       \n",
       "43                                           2.704225                       \n",
       "63                                          -0.129577                       \n",
       "83                                          -0.149296                       \n",
       "\n",
       "    RanAdults (ages 15+) newly infected with HIV  \\\n",
       "3                                       2.755945   \n",
       "23                                      0.867859   \n",
       "43                                     -0.150461   \n",
       "63                                      4.408828   \n",
       "83                                      0.003332   \n",
       "\n",
       "    RanAir transport, passengers carried  \\\n",
       "3                              -1.024735   \n",
       "23                              0.236749   \n",
       "43                             -0.706714   \n",
       "63                             -1.272085   \n",
       "83                             -1.091873   \n",
       "\n",
       "    RanBirths attended by skilled health staff (% of total)  ...  \\\n",
       "3                                           -8.144928        ...   \n",
       "23                                          -8.144928        ...   \n",
       "43                                          -0.009662        ...   \n",
       "63                                           0.067633        ...   \n",
       "83                                          -8.183575        ...   \n",
       "\n",
       "    RanTime required to build a warehouse (days)  \\\n",
       "3                                       0.267800   \n",
       "23                                      0.236322   \n",
       "43                                      0.828286   \n",
       "63                                      0.839712   \n",
       "83                                      0.628571   \n",
       "\n",
       "    RanTotal alcohol consumption per capita (liters of pure alcohol, projected estimates, 15+ years of age)  \\\n",
       "3                                            0.183283                                                         \n",
       "23                                           0.496831                                                         \n",
       "43                                           1.469515                                                         \n",
       "63                                           2.298701                                                         \n",
       "83                                          -0.426049                                                         \n",
       "\n",
       "    RanTotal debt service (% of GNI)  RanTrade (% of GDP)  \\\n",
       "3                           0.025734            -0.410519   \n",
       "23                         -0.206206             0.252292   \n",
       "43                          0.468565            -0.414294   \n",
       "63                         -0.774922             0.340398   \n",
       "83                         -1.022001            -0.739529   \n",
       "\n",
       "    RanTravel services (% of commercial service exports)  \\\n",
       "3                                            0.036473      \n",
       "23                                          -0.592593      \n",
       "43                                           0.259259      \n",
       "63                                          -1.148148      \n",
       "83                                           0.531565      \n",
       "\n",
       "    RanUHC service coverage index  \\\n",
       "3                        0.200669   \n",
       "23                       0.432318   \n",
       "43                       0.783168   \n",
       "63                      -0.314381   \n",
       "83                      -0.548495   \n",
       "\n",
       "    RanUnmet need for contraception (% of married women ages 15-49)  \\\n",
       "3                                           -0.912738                 \n",
       "23                                          -0.912738                 \n",
       "43                                          -0.095624                 \n",
       "63                                           0.705979                 \n",
       "83                                          -0.832416                 \n",
       "\n",
       "    RanUrban population (% of total population)  Country Name  Year  \n",
       "3                                      0.693920             0  2003  \n",
       "23                                    -1.038138             0  2003  \n",
       "43                                     0.894716             5  2003  \n",
       "63                                     0.238265            10  2003  \n",
       "83                                    -0.169141            15  2003  \n",
       "\n",
       "[5 rows x 139 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>ARI treatment (% of children under 5 taken to a health provider)</th>\n",
       "      <th>Access to electricity (% of population)</th>\n",
       "      <th>Adjusted net national income (annual % growth)</th>\n",
       "      <th>Adjusted net national income per capita (annual % growth)</th>\n",
       "      <th>Adolescents out of school (% of lower secondary school age)</th>\n",
       "      <th>Adults (ages 15+) and children (ages 0-14) newly infected with HIV</th>\n",
       "      <th>Adults (ages 15+) newly infected with HIV</th>\n",
       "      <th>Air transport, passengers carried</th>\n",
       "      <th>...</th>\n",
       "      <th>Suicide mortality rate (per 100,000 population)</th>\n",
       "      <th>Time required to build a warehouse (days)</th>\n",
       "      <th>Total alcohol consumption per capita (liters of pure alcohol, projected estimates, 15+ years of age)</th>\n",
       "      <th>Total debt service (% of GNI)</th>\n",
       "      <th>Trade (% of GDP)</th>\n",
       "      <th>Travel services (% of commercial service exports)</th>\n",
       "      <th>UHC service coverage index</th>\n",
       "      <th>Unmet need for contraception (% of married women ages 15-49)</th>\n",
       "      <th>Urban population (% of total population)</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.012935</td>\n",
       "      <td>-0.386626</td>\n",
       "      <td>-0.433758</td>\n",
       "      <td>0.394811</td>\n",
       "      <td>-0.179372</td>\n",
       "      <td>-0.183099</td>\n",
       "      <td>-0.155835</td>\n",
       "      <td>0.123418</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.586779</td>\n",
       "      <td>0.219263</td>\n",
       "      <td>0.143918</td>\n",
       "      <td>0.234258</td>\n",
       "      <td>0.106814</td>\n",
       "      <td>0.474648</td>\n",
       "      <td>0.545838</td>\n",
       "      <td>-0.919919</td>\n",
       "      <td>-0.748563</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>0.015797</td>\n",
       "      <td>-0.417269</td>\n",
       "      <td>-0.447410</td>\n",
       "      <td>0.041233</td>\n",
       "      <td>-0.179372</td>\n",
       "      <td>-0.183099</td>\n",
       "      <td>-0.126965</td>\n",
       "      <td>0.279530</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.803339</td>\n",
       "      <td>0.215033</td>\n",
       "      <td>0.076124</td>\n",
       "      <td>-0.067477</td>\n",
       "      <td>0.114925</td>\n",
       "      <td>0.475470</td>\n",
       "      <td>0.532083</td>\n",
       "      <td>-0.917543</td>\n",
       "      <td>-1.015094</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>-0.097191</td>\n",
       "      <td>-0.011682</td>\n",
       "      <td>-0.204523</td>\n",
       "      <td>0.554581</td>\n",
       "      <td>-0.179372</td>\n",
       "      <td>-0.183099</td>\n",
       "      <td>-0.157732</td>\n",
       "      <td>0.155739</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.034160</td>\n",
       "      <td>-0.229558</td>\n",
       "      <td>-0.098894</td>\n",
       "      <td>-0.263153</td>\n",
       "      <td>0.257364</td>\n",
       "      <td>-0.690371</td>\n",
       "      <td>0.778602</td>\n",
       "      <td>-0.915141</td>\n",
       "      <td>-1.984476</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>-1.239797</td>\n",
       "      <td>-0.122472</td>\n",
       "      <td>-0.311924</td>\n",
       "      <td>0.352224</td>\n",
       "      <td>-0.179372</td>\n",
       "      <td>-0.183099</td>\n",
       "      <td>-0.153575</td>\n",
       "      <td>0.158801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.899734</td>\n",
       "      <td>-0.096437</td>\n",
       "      <td>-0.070336</td>\n",
       "      <td>-0.308676</td>\n",
       "      <td>0.340158</td>\n",
       "      <td>-0.338374</td>\n",
       "      <td>0.722582</td>\n",
       "      <td>-0.912738</td>\n",
       "      <td>-1.857038</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>-0.087712</td>\n",
       "      <td>0.585151</td>\n",
       "      <td>0.350082</td>\n",
       "      <td>0.466900</td>\n",
       "      <td>-0.179372</td>\n",
       "      <td>-0.183099</td>\n",
       "      <td>-0.157322</td>\n",
       "      <td>0.178543</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.034125</td>\n",
       "      <td>-0.226018</td>\n",
       "      <td>-0.590060</td>\n",
       "      <td>-0.426091</td>\n",
       "      <td>0.277581</td>\n",
       "      <td>-0.340698</td>\n",
       "      <td>0.824597</td>\n",
       "      <td>-0.908900</td>\n",
       "      <td>-2.439187</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country Name    Year  \\\n",
       "0             0  2000.0   \n",
       "1             0  2001.0   \n",
       "2             0  2002.0   \n",
       "3             0  2003.0   \n",
       "4             0  2004.0   \n",
       "\n",
       "   ARI treatment (% of children under 5 taken to a health provider)  \\\n",
       "0                                           0.012935                  \n",
       "1                                           0.015797                  \n",
       "2                                          -0.097191                  \n",
       "3                                          -1.239797                  \n",
       "4                                          -0.087712                  \n",
       "\n",
       "   Access to electricity (% of population)  \\\n",
       "0                                -0.386626   \n",
       "1                                -0.417269   \n",
       "2                                -0.011682   \n",
       "3                                -0.122472   \n",
       "4                                 0.585151   \n",
       "\n",
       "   Adjusted net national income (annual % growth)  \\\n",
       "0                                       -0.433758   \n",
       "1                                       -0.447410   \n",
       "2                                       -0.204523   \n",
       "3                                       -0.311924   \n",
       "4                                        0.350082   \n",
       "\n",
       "   Adjusted net national income per capita (annual % growth)  \\\n",
       "0                                           0.394811           \n",
       "1                                           0.041233           \n",
       "2                                           0.554581           \n",
       "3                                           0.352224           \n",
       "4                                           0.466900           \n",
       "\n",
       "   Adolescents out of school (% of lower secondary school age)  \\\n",
       "0                                          -0.179372             \n",
       "1                                          -0.179372             \n",
       "2                                          -0.179372             \n",
       "3                                          -0.179372             \n",
       "4                                          -0.179372             \n",
       "\n",
       "   Adults (ages 15+) and children (ages 0-14) newly infected with HIV  \\\n",
       "0                                          -0.183099                    \n",
       "1                                          -0.183099                    \n",
       "2                                          -0.183099                    \n",
       "3                                          -0.183099                    \n",
       "4                                          -0.183099                    \n",
       "\n",
       "   Adults (ages 15+) newly infected with HIV  \\\n",
       "0                                  -0.155835   \n",
       "1                                  -0.126965   \n",
       "2                                  -0.157732   \n",
       "3                                  -0.153575   \n",
       "4                                  -0.157322   \n",
       "\n",
       "   Air transport, passengers carried  ...  \\\n",
       "0                           0.123418  ...   \n",
       "1                           0.279530  ...   \n",
       "2                           0.155739  ...   \n",
       "3                           0.158801  ...   \n",
       "4                           0.178543  ...   \n",
       "\n",
       "   Suicide mortality rate (per 100,000 population)  \\\n",
       "0                                        -0.586779   \n",
       "1                                        -0.803339   \n",
       "2                                        -1.034160   \n",
       "3                                         0.899734   \n",
       "4                                        -1.034125   \n",
       "\n",
       "   Time required to build a warehouse (days)  \\\n",
       "0                                   0.219263   \n",
       "1                                   0.215033   \n",
       "2                                  -0.229558   \n",
       "3                                  -0.096437   \n",
       "4                                  -0.226018   \n",
       "\n",
       "   Total alcohol consumption per capita (liters of pure alcohol, projected estimates, 15+ years of age)  \\\n",
       "0                                           0.143918                                                      \n",
       "1                                           0.076124                                                      \n",
       "2                                          -0.098894                                                      \n",
       "3                                          -0.070336                                                      \n",
       "4                                          -0.590060                                                      \n",
       "\n",
       "   Total debt service (% of GNI)  Trade (% of GDP)  \\\n",
       "0                       0.234258          0.106814   \n",
       "1                      -0.067477          0.114925   \n",
       "2                      -0.263153          0.257364   \n",
       "3                      -0.308676          0.340158   \n",
       "4                      -0.426091          0.277581   \n",
       "\n",
       "   Travel services (% of commercial service exports)  \\\n",
       "0                                           0.474648   \n",
       "1                                           0.475470   \n",
       "2                                          -0.690371   \n",
       "3                                          -0.338374   \n",
       "4                                          -0.340698   \n",
       "\n",
       "   UHC service coverage index  \\\n",
       "0                    0.545838   \n",
       "1                    0.532083   \n",
       "2                    0.778602   \n",
       "3                    0.722582   \n",
       "4                    0.824597   \n",
       "\n",
       "   Unmet need for contraception (% of married women ages 15-49)  \\\n",
       "0                                          -0.919919              \n",
       "1                                          -0.917543              \n",
       "2                                          -0.915141              \n",
       "3                                          -0.912738              \n",
       "4                                          -0.908900              \n",
       "\n",
       "   Urban population (% of total population)  Label  \n",
       "0                                 -0.748563    1.0  \n",
       "1                                 -1.015094    1.0  \n",
       "2                                 -1.984476    1.0  \n",
       "3                                 -1.857038    1.0  \n",
       "4                                 -2.439187    0.0  \n",
       "\n",
       "[5 rows x 139 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_h = pd.read_csv('Harsh_Imputed_Scaled.csv')\n",
    "df_h.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "df_h.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:282: UserWarning: The total space of parameters 20 is smaller than n_iter=100. Running 20 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  4.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9300499643112062\n",
      "F1 score: 0.9300531717337002\n",
      "Recall: 0.9300499643112062\n",
      "Precision: 0.9309096070471425\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.91      0.93       717\n",
      "         1.0       0.91      0.95      0.93       684\n",
      "\n",
      "    accuracy                           0.93      1401\n",
      "   macro avg       0.93      0.93      0.93      1401\n",
      "weighted avg       0.93      0.93      0.93      1401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [160, 170, 180, 190, 200]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "#max_depth = [10, 20, 30]\n",
    "#max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "#min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "#min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               #'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "               #'max_depth': max_depth}\n",
    "\n",
    "#               'min_samples_split': min_samples_split,\n",
    "\n",
    "\n",
    "rnd1 = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rnd1, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "X = df_h.iloc[:, :-1]\n",
    "y = df_h['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_random.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:282: UserWarning: The total space of parameters 20 is smaller than n_iter=100. Running 20 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8469626168224299\n",
      "F1 score: 0.8233867827488787\n",
      "Recall: 0.8469626168224299\n",
      "Precision: 0.8313342587384972\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.97      0.91       694\n",
      "         1.0       0.71      0.33      0.45       162\n",
      "\n",
      "    accuracy                           0.85       856\n",
      "   macro avg       0.78      0.65      0.68       856\n",
      "weighted avg       0.83      0.85      0.82       856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [160, 170, 180, 190, 200]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "#max_depth = [10, 20, 30]\n",
    "#max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "#min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "#min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               #'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "               #'max_depth': max_depth}\n",
    "\n",
    "#               'min_samples_split': min_samples_split,\n",
    "\n",
    "\n",
    "rnd1 = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rnd1, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "X = df_h.iloc[:, :-1]\n",
    "y = df_h['Label']\n",
    "\n",
    "#smt = SMOTETomek(sampling_strategy='all')\n",
    "#X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_random.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 160, 'max_features': 'sqrt', 'bootstrap': False}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2. Ensemble Methods</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>A. Random Forest Classifier</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9081272084805654\n",
      "F1 score: 0.9081180285453615\n",
      "Recall: 0.9081272084805654\n",
      "Precision: 0.9081669315009286\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.90      0.91       699\n",
      "         1.0       0.90      0.91      0.91       716\n",
      "\n",
      "    accuracy                           0.91      1415\n",
      "   macro avg       0.91      0.91      0.91      1415\n",
      "weighted avg       0.91      0.91      0.91      1415\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnd1 = RandomForestClassifier()\n",
    "X = df_1.iloc[:, :-1]\n",
    "y = df_1['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "\n",
    "rnd1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rnd1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9214131218457101\n",
      "F1 score: 0.9214118963085153\n",
      "Recall: 0.9214131218457101\n",
      "Precision: 0.921434620292101\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.93      0.92       694\n",
      "         1.0       0.92      0.92      0.92       693\n",
      "\n",
      "    accuracy                           0.92      1387\n",
      "   macro avg       0.92      0.92      0.92      1387\n",
      "weighted avg       0.92      0.92      0.92      1387\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnd1 = RandomForestClassifier()\n",
    "X = df_2.iloc[:, :-1]\n",
    "y = df_2['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "\n",
    "rnd1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rnd1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9129511677282378\n",
      "F1 score: 0.9129516909229574\n",
      "Recall: 0.9129511677282378\n",
      "Precision: 0.9129604447941797\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.91      0.91       703\n",
      "         1.0       0.92      0.91      0.91       710\n",
      "\n",
      "    accuracy                           0.91      1413\n",
      "   macro avg       0.91      0.91      0.91      1413\n",
      "weighted avg       0.91      0.91      0.91      1413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnd1 = RandomForestClassifier()\n",
    "X = df_3.iloc[:, :-1]\n",
    "y = df_3['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "\n",
    "rnd1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rnd1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9078374455732946\n",
      "F1 score: 0.9078184654544273\n",
      "Recall: 0.9078374455732946\n",
      "Precision: 0.9083057048849502\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.89      0.91       692\n",
      "         1.0       0.89      0.92      0.91       686\n",
      "\n",
      "    accuracy                           0.91      1378\n",
      "   macro avg       0.91      0.91      0.91      1378\n",
      "weighted avg       0.91      0.91      0.91      1378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnd1 = RandomForestClassifier()\n",
    "X = df_4.iloc[:, :-1]\n",
    "y = df_4['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "\n",
    "rnd1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rnd1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.917963224893918\n",
      "F1 score: 0.9179454967246244\n",
      "Recall: 0.917963224893918\n",
      "Precision: 0.9184571165923819\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.90      0.92       710\n",
      "         1.0       0.90      0.93      0.92       704\n",
      "\n",
      "    accuracy                           0.92      1414\n",
      "   macro avg       0.92      0.92      0.92      1414\n",
      "weighted avg       0.92      0.92      0.92      1414\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnd1 = RandomForestClassifier()\n",
    "X = df_5.iloc[:, :-1]\n",
    "y = df_5['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "\n",
    "rnd1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rnd1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.836046511627907\n",
      "F1 score: 0.8026196246328041\n",
      "Recall: 0.836046511627907\n",
      "Precision: 0.7979986889400312\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.96      0.91       720\n",
      "         1.0       0.49      0.18      0.26       140\n",
      "\n",
      "    accuracy                           0.84       860\n",
      "   macro avg       0.67      0.57      0.58       860\n",
      "weighted avg       0.80      0.84      0.80       860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnd1 = RandomForestClassifier()\n",
    "X = df_6.iloc[:, :-1]\n",
    "y = df_6['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "rnd1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rnd1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9268635724331927\n",
      "F1 score: 0.9268794898704033\n",
      "Recall: 0.9268635724331927\n",
      "Precision: 0.9273391045557468\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.91      0.93       732\n",
      "         1.0       0.91      0.94      0.93       690\n",
      "\n",
      "    accuracy                           0.93      1422\n",
      "   macro avg       0.93      0.93      0.93      1422\n",
      "weighted avg       0.93      0.93      0.93      1422\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnd1 = RandomForestClassifier()\n",
    "X = df_7.iloc[:, :-1]\n",
    "y = df_7['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "rnd1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rnd1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9095513748191028\n",
      "F1 score: 0.9095490542574776\n",
      "Recall: 0.9095513748191028\n",
      "Precision: 0.909593408066489\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.90      0.91       691\n",
      "         1.0       0.91      0.91      0.91       691\n",
      "\n",
      "    accuracy                           0.91      1382\n",
      "   macro avg       0.91      0.91      0.91      1382\n",
      "weighted avg       0.91      0.91      0.91      1382\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnd1 = RandomForestClassifier()\n",
    "X = df_8.iloc[:, :-1]\n",
    "y = df_8['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "\n",
    "rnd1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rnd1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>B. Voting Classifier</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7796610169491526\n",
      "F1 score: 0.7796539836567926\n",
      "Recall: 0.7796610169491526\n",
      "Precision: 0.7796967278531525\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.79      0.78       708\n",
      "         1.0       0.78      0.77      0.78       708\n",
      "\n",
      "    accuracy                           0.78      1416\n",
      "   macro avg       0.78      0.78      0.78      1416\n",
      "weighted avg       0.78      0.78      0.78      1416\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Data\n",
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "voting='hard')\n",
    "\n",
    "X = df_1.iloc[:, :-1]\n",
    "y = df_1['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7985507246376812\n",
      "F1 score: 0.7985507246376812\n",
      "Recall: 0.7985507246376812\n",
      "Precision: 0.7985507246376812\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.80      0.80       693\n",
      "         1.0       0.80      0.80      0.80       687\n",
      "\n",
      "    accuracy                           0.80      1380\n",
      "   macro avg       0.80      0.80      0.80      1380\n",
      "weighted avg       0.80      0.80      0.80      1380\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Data\n",
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "voting='hard')\n",
    "\n",
    "X = df_2.iloc[:, :-1]\n",
    "y = df_2['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.759915014164306\n",
      "F1 score: 0.755897141051076\n",
      "Recall: 0.759915014164306\n",
      "Precision: 0.783117710243167\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.90      0.79       691\n",
      "         1.0       0.86      0.63      0.73       721\n",
      "\n",
      "    accuracy                           0.76      1412\n",
      "   macro avg       0.78      0.76      0.76      1412\n",
      "weighted avg       0.78      0.76      0.76      1412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Data\n",
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "voting='hard')\n",
    "\n",
    "X = df_3.iloc[:, :-1]\n",
    "y = df_3['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7976625273922571\n",
      "F1 score: 0.7975586308312232\n",
      "Recall: 0.7976625273922571\n",
      "Precision: 0.7986221629284496\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.82      0.80       679\n",
      "         1.0       0.82      0.77      0.79       690\n",
      "\n",
      "    accuracy                           0.80      1369\n",
      "   macro avg       0.80      0.80      0.80      1369\n",
      "weighted avg       0.80      0.80      0.80      1369\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Data\n",
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "voting='hard')\n",
    "\n",
    "X = df_4.iloc[:, :-1]\n",
    "y = df_4['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7572335920959774\n",
      "F1 score: 0.7541343030425108\n",
      "Recall: 0.7572335920959774\n",
      "Precision: 0.7765243249537231\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.88      0.78       689\n",
      "         1.0       0.85      0.64      0.73       728\n",
      "\n",
      "    accuracy                           0.76      1417\n",
      "   macro avg       0.77      0.76      0.75      1417\n",
      "weighted avg       0.78      0.76      0.75      1417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Data\n",
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "voting='hard')\n",
    "\n",
    "X = df_5.iloc[:, :-1]\n",
    "y = df_5['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7937771345875543\n",
      "F1 score: 0.793633857807354\n",
      "Recall: 0.7937771345875543\n",
      "Precision: 0.7940112565856693\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.77      0.79       677\n",
      "         1.0       0.79      0.82      0.80       705\n",
      "\n",
      "    accuracy                           0.79      1382\n",
      "   macro avg       0.79      0.79      0.79      1382\n",
      "weighted avg       0.79      0.79      0.79      1382\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Data\n",
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "voting='hard')\n",
    "\n",
    "X = df_6.iloc[:, :-1]\n",
    "y = df_6['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7860661505981703\n",
      "F1 score: 0.7857516156547643\n",
      "Recall: 0.7860661505981703\n",
      "Precision: 0.7875521052267276\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.82      0.79       713\n",
      "         1.0       0.81      0.75      0.78       708\n",
      "\n",
      "    accuracy                           0.79      1421\n",
      "   macro avg       0.79      0.79      0.79      1421\n",
      "weighted avg       0.79      0.79      0.79      1421\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Data\n",
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "voting='hard')\n",
    "\n",
    "X = df_7.iloc[:, :-1]\n",
    "y = df_7['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7673410404624278\n",
      "F1 score: 0.7669828740700645\n",
      "Recall: 0.7673410404624278\n",
      "Precision: 0.7811873295501922\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.70      0.76       748\n",
      "         1.0       0.70      0.85      0.77       636\n",
      "\n",
      "    accuracy                           0.77      1384\n",
      "   macro avg       0.78      0.77      0.77      1384\n",
      "weighted avg       0.78      0.77      0.77      1384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Data\n",
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "voting='hard')\n",
    "\n",
    "X = df_8.iloc[:, :-1]\n",
    "y = df_8['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>C. Bagging Classifier</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9066478076379066\n",
      "F1 score: 0.906653970854832\n",
      "Recall: 0.9066478076379066\n",
      "Precision: 0.9070991417398591\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.92      0.91       693\n",
      "         1.0       0.92      0.89      0.91       721\n",
      "\n",
      "    accuracy                           0.91      1414\n",
      "   macro avg       0.91      0.91      0.91      1414\n",
      "weighted avg       0.91      0.91      0.91      1414\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_bagging.py:638: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_bagging.py:643: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions.sum(axis=1)[:, np.newaxis])\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "bc1 = BaggingClassifier(base_estimator=dt, oob_score=True, random_state=1)\n",
    "\n",
    "X = df_1.iloc[:, :-1]\n",
    "y = df_1['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "#classifier = RandomForestClassifier()\n",
    "bc1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = bc1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8847262247838616\n",
      "F1 score: 0.8847185659056997\n",
      "Recall: 0.8847262247838616\n",
      "Precision: 0.8856520323795076\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.86      0.88       708\n",
      "         1.0       0.87      0.91      0.89       680\n",
      "\n",
      "    accuracy                           0.88      1388\n",
      "   macro avg       0.89      0.89      0.88      1388\n",
      "weighted avg       0.89      0.88      0.88      1388\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_bagging.py:638: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_bagging.py:643: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  predictions.sum(axis=1)[:, np.newaxis])\n",
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_bagging.py:643: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions.sum(axis=1)[:, np.newaxis])\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "bc1 = BaggingClassifier(base_estimator=dt, oob_score=True, random_state=1)\n",
    "\n",
    "X = df_2.iloc[:, :-1]\n",
    "y = df_2['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "#classifier = RandomForestClassifier()\n",
    "bc1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = bc1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8881811748053786\n",
      "F1 score: 0.888117224480934\n",
      "Recall: 0.8881811748053786\n",
      "Precision: 0.8884100449267469\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.87      0.88       688\n",
      "         1.0       0.88      0.90      0.89       725\n",
      "\n",
      "    accuracy                           0.89      1413\n",
      "   macro avg       0.89      0.89      0.89      1413\n",
      "weighted avg       0.89      0.89      0.89      1413\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_bagging.py:638: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_bagging.py:643: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions.sum(axis=1)[:, np.newaxis])\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "bc1 = BaggingClassifier(base_estimator=dt, oob_score=True, random_state=1)\n",
    "\n",
    "X = df_3.iloc[:, :-1]\n",
    "y = df_3['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "#classifier = RandomForestClassifier()\n",
    "bc1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = bc1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8624454148471615\n",
      "F1 score: 0.8623686292059827\n",
      "Recall: 0.8624454148471615\n",
      "Precision: 0.8629592163775489\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.88      0.87       693\n",
      "         1.0       0.88      0.84      0.86       681\n",
      "\n",
      "    accuracy                           0.86      1374\n",
      "   macro avg       0.86      0.86      0.86      1374\n",
      "weighted avg       0.86      0.86      0.86      1374\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_bagging.py:638: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_bagging.py:643: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  predictions.sum(axis=1)[:, np.newaxis])\n",
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_bagging.py:643: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions.sum(axis=1)[:, np.newaxis])\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "bc1 = BaggingClassifier(base_estimator=dt, oob_score=True, random_state=1)\n",
    "\n",
    "X = df_4.iloc[:, :-1]\n",
    "y = df_4['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "#classifier = RandomForestClassifier()\n",
    "bc1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = bc1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8997175141242938\n",
      "F1 score: 0.8997189145416418\n",
      "Recall: 0.8997175141242938\n",
      "Precision: 0.8998962277460116\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.91      0.90       700\n",
      "         1.0       0.91      0.89      0.90       716\n",
      "\n",
      "    accuracy                           0.90      1416\n",
      "   macro avg       0.90      0.90      0.90      1416\n",
      "weighted avg       0.90      0.90      0.90      1416\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_bagging.py:638: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_bagging.py:643: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  predictions.sum(axis=1)[:, np.newaxis])\n",
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_bagging.py:643: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions.sum(axis=1)[:, np.newaxis])\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "bc1 = BaggingClassifier(base_estimator=dt, oob_score=True, random_state=1)\n",
    "\n",
    "X = df_5.iloc[:, :-1]\n",
    "y = df_5['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "#classifier = RandomForestClassifier()\n",
    "bc1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = bc1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8806078147612156\n",
      "F1 score: 0.8805924896180771\n",
      "Recall: 0.8806078147612156\n",
      "Precision: 0.8806223824049559\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.89      0.88       705\n",
      "         1.0       0.88      0.87      0.88       677\n",
      "\n",
      "    accuracy                           0.88      1382\n",
      "   macro avg       0.88      0.88      0.88      1382\n",
      "weighted avg       0.88      0.88      0.88      1382\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_bagging.py:638: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_bagging.py:643: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  predictions.sum(axis=1)[:, np.newaxis])\n",
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_bagging.py:643: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions.sum(axis=1)[:, np.newaxis])\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "bc1 = BaggingClassifier(base_estimator=dt, oob_score=True, random_state=1)\n",
    "\n",
    "X = df_6.iloc[:, :-1]\n",
    "y = df_6['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "#classifier = RandomForestClassifier()\n",
    "bc1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = bc1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8807339449541285\n",
      "F1 score: 0.8807428587589659\n",
      "Recall: 0.8807339449541285\n",
      "Precision: 0.8807737087887619\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.88      0.88       726\n",
      "         1.0       0.88      0.88      0.88       691\n",
      "\n",
      "    accuracy                           0.88      1417\n",
      "   macro avg       0.88      0.88      0.88      1417\n",
      "weighted avg       0.88      0.88      0.88      1417\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_bagging.py:638: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_bagging.py:643: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  predictions.sum(axis=1)[:, np.newaxis])\n",
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_bagging.py:643: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions.sum(axis=1)[:, np.newaxis])\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "bc1 = BaggingClassifier(base_estimator=dt, oob_score=True, random_state=1)\n",
    "\n",
    "X = df_7.iloc[:, :-1]\n",
    "y = df_7['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "#classifier = RandomForestClassifier()\n",
    "bc1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = bc1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8647866955892987\n",
      "F1 score: 0.8647738249543172\n",
      "Recall: 0.8647866955892987\n",
      "Precision: 0.8648052828739619\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.87      0.87       701\n",
      "         1.0       0.87      0.86      0.86       682\n",
      "\n",
      "    accuracy                           0.86      1383\n",
      "   macro avg       0.86      0.86      0.86      1383\n",
      "weighted avg       0.86      0.86      0.86      1383\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_bagging.py:638: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_bagging.py:643: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  predictions.sum(axis=1)[:, np.newaxis])\n",
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_bagging.py:643: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions.sum(axis=1)[:, np.newaxis])\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "bc1 = BaggingClassifier(base_estimator=dt, oob_score=True, random_state=1)\n",
    "\n",
    "X = df_8.iloc[:, :-1]\n",
    "y = df_8['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "#classifier = RandomForestClassifier()\n",
    "bc1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = bc1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>D. Adaboost Classifier</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8346289752650177\n",
      "F1 score: 0.8345010021508182\n",
      "Recall: 0.8346289752650177\n",
      "Precision: 0.8354563213816737\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.81      0.83       704\n",
      "         1.0       0.82      0.86      0.84       711\n",
      "\n",
      "    accuracy                           0.83      1415\n",
      "   macro avg       0.84      0.83      0.83      1415\n",
      "weighted avg       0.84      0.83      0.83      1415\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_1.iloc[:, :-1]\n",
    "y = df_1['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "ad1 = AdaBoostClassifier()\n",
    "ad1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ad1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7739130434782608\n",
      "F1 score: 0.7738631582553877\n",
      "Recall: 0.7739130434782608\n",
      "Precision: 0.7739726823831574\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.76      0.77       682\n",
      "         1.0       0.77      0.79      0.78       698\n",
      "\n",
      "    accuracy                           0.77      1380\n",
      "   macro avg       0.77      0.77      0.77      1380\n",
      "weighted avg       0.77      0.77      0.77      1380\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_2.iloc[:, :-1]\n",
    "y = df_2['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "ad1 = AdaBoostClassifier()\n",
    "ad1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ad1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7880935506732814\n",
      "F1 score: 0.7877287088752367\n",
      "Recall: 0.7880935506732814\n",
      "Precision: 0.7901350003163153\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.75      0.78       706\n",
      "         1.0       0.77      0.83      0.80       705\n",
      "\n",
      "    accuracy                           0.79      1411\n",
      "   macro avg       0.79      0.79      0.79      1411\n",
      "weighted avg       0.79      0.79      0.79      1411\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_3.iloc[:, :-1]\n",
    "y = df_3['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "ad1 = AdaBoostClassifier()\n",
    "ad1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ad1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7681686046511628\n",
      "F1 score: 0.7682843406212857\n",
      "Recall: 0.7681686046511628\n",
      "Precision: 0.7700437336590065\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.75      0.77       721\n",
      "         1.0       0.74      0.79      0.76       655\n",
      "\n",
      "    accuracy                           0.77      1376\n",
      "   macro avg       0.77      0.77      0.77      1376\n",
      "weighted avg       0.77      0.77      0.77      1376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_4.iloc[:, :-1]\n",
    "y = df_4['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "ad1 = AdaBoostClassifier()\n",
    "ad1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ad1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7977448907681466\n",
      "F1 score: 0.7976341193118279\n",
      "Recall: 0.7977448907681466\n",
      "Precision: 0.798190886056282\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.78      0.79       705\n",
      "         1.0       0.79      0.82      0.80       714\n",
      "\n",
      "    accuracy                           0.80      1419\n",
      "   macro avg       0.80      0.80      0.80      1419\n",
      "weighted avg       0.80      0.80      0.80      1419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_5.iloc[:, :-1]\n",
    "y = df_5['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "ad1 = AdaBoostClassifier()\n",
    "ad1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ad1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7942028985507247\n",
      "F1 score: 0.7939416658805301\n",
      "Recall: 0.7942028985507247\n",
      "Precision: 0.7943372914696079\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.76      0.78       661\n",
      "         1.0       0.79      0.82      0.81       719\n",
      "\n",
      "    accuracy                           0.79      1380\n",
      "   macro avg       0.79      0.79      0.79      1380\n",
      "weighted avg       0.79      0.79      0.79      1380\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_6.iloc[:, :-1]\n",
    "y = df_6['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "ad1 = AdaBoostClassifier()\n",
    "ad1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ad1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8119718309859155\n",
      "F1 score: 0.8119032509845632\n",
      "Recall: 0.8119718309859155\n",
      "Precision: 0.8121902612297778\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.80      0.81       703\n",
      "         1.0       0.80      0.83      0.82       717\n",
      "\n",
      "    accuracy                           0.81      1420\n",
      "   macro avg       0.81      0.81      0.81      1420\n",
      "weighted avg       0.81      0.81      0.81      1420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_7.iloc[:, :-1]\n",
    "y = df_7['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "ad1 = AdaBoostClassifier()\n",
    "ad1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ad1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7891304347826087\n",
      "F1 score: 0.7889481707055886\n",
      "Recall: 0.7891304347826087\n",
      "Precision: 0.7906020334070862\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.76      0.78       696\n",
      "         1.0       0.77      0.82      0.79       684\n",
      "\n",
      "    accuracy                           0.79      1380\n",
      "   macro avg       0.79      0.79      0.79      1380\n",
      "weighted avg       0.79      0.79      0.79      1380\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_8.iloc[:, :-1]\n",
    "y = df_8['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "ad1 = AdaBoostClassifier()\n",
    "ad1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ad1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>E. Gradient Boosting Algorithm</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8684582743988685\n",
      "F1 score: 0.8684730129675634\n",
      "Recall: 0.8684582743988685\n",
      "Precision: 0.8687101416312878\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.86      0.87       722\n",
      "         1.0       0.86      0.88      0.87       692\n",
      "\n",
      "    accuracy                           0.87      1414\n",
      "   macro avg       0.87      0.87      0.87      1414\n",
      "weighted avg       0.87      0.87      0.87      1414\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_1.iloc[:, :-1]\n",
    "y = df_1['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "gb1 = GradientBoostingClassifier()\n",
    "gb1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gb1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8359941944847605\n",
      "F1 score: 0.8359167753805293\n",
      "Recall: 0.8359941944847605\n",
      "Precision: 0.8367424821856125\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.81      0.83       691\n",
      "         1.0       0.82      0.86      0.84       687\n",
      "\n",
      "    accuracy                           0.84      1378\n",
      "   macro avg       0.84      0.84      0.84      1378\n",
      "weighted avg       0.84      0.84      0.84      1378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_2.iloc[:, :-1]\n",
    "y = df_2['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "gb1 = GradientBoostingClassifier()\n",
    "gb1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gb1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8407643312101911\n",
      "F1 score: 0.8405262925225343\n",
      "Recall: 0.8407643312101911\n",
      "Precision: 0.8445585163390341\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.79      0.84       721\n",
      "         1.0       0.81      0.89      0.85       692\n",
      "\n",
      "    accuracy                           0.84      1413\n",
      "   macro avg       0.84      0.84      0.84      1413\n",
      "weighted avg       0.84      0.84      0.84      1413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_3.iloc[:, :-1]\n",
    "y = df_3['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "gb1 = GradientBoostingClassifier()\n",
    "gb1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gb1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.862873814733771\n",
      "F1 score: 0.8626456873753445\n",
      "Recall: 0.862873814733771\n",
      "Precision: 0.8645453032676564\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.83      0.86       677\n",
      "         1.0       0.84      0.90      0.87       694\n",
      "\n",
      "    accuracy                           0.86      1371\n",
      "   macro avg       0.86      0.86      0.86      1371\n",
      "weighted avg       0.86      0.86      0.86      1371\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_4.iloc[:, :-1]\n",
    "y = df_4['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "gb1 = GradientBoostingClassifier()\n",
    "gb1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gb1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8712871287128713\n",
      "F1 score: 0.8712685402644362\n",
      "Recall: 0.8712871287128713\n",
      "Precision: 0.8712639259832927\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.86      0.86       673\n",
      "         1.0       0.88      0.88      0.88       741\n",
      "\n",
      "    accuracy                           0.87      1414\n",
      "   macro avg       0.87      0.87      0.87      1414\n",
      "weighted avg       0.87      0.87      0.87      1414\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_5.iloc[:, :-1]\n",
    "y = df_5['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "gb1 = GradientBoostingClassifier()\n",
    "gb1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gb1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8476534296028881\n",
      "F1 score: 0.8476113344931792\n",
      "Recall: 0.8476534296028881\n",
      "Precision: 0.8500567808802972\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.82      0.85       714\n",
      "         1.0       0.82      0.88      0.85       671\n",
      "\n",
      "    accuracy                           0.85      1385\n",
      "   macro avg       0.85      0.85      0.85      1385\n",
      "weighted avg       0.85      0.85      0.85      1385\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_6.iloc[:, :-1]\n",
    "y = df_6['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "gb1 = GradientBoostingClassifier()\n",
    "gb1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gb1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8567395906845449\n",
      "F1 score: 0.8567579989971073\n",
      "Recall: 0.8567395906845449\n",
      "Precision: 0.8583553958484895\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.83      0.86       733\n",
      "         1.0       0.83      0.88      0.86       684\n",
      "\n",
      "    accuracy                           0.86      1417\n",
      "   macro avg       0.86      0.86      0.86      1417\n",
      "weighted avg       0.86      0.86      0.86      1417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_7.iloc[:, :-1]\n",
    "y = df_7['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "gb1 = GradientBoostingClassifier()\n",
    "gb1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gb1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8427947598253275\n",
      "F1 score: 0.8426627232279613\n",
      "Recall: 0.8427947598253275\n",
      "Precision: 0.8436911293865622\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.82      0.84       683\n",
      "         1.0       0.83      0.87      0.85       691\n",
      "\n",
      "    accuracy                           0.84      1374\n",
      "   macro avg       0.84      0.84      0.84      1374\n",
      "weighted avg       0.84      0.84      0.84      1374\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_8.iloc[:, :-1]\n",
    "y = df_8['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "gb1 = GradientBoostingClassifier()\n",
    "gb1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gb1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>3. SGD Classifier</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6173974540311173\n",
      "F1 score: 0.5856462872900047\n",
      "Recall: 0.6173974540311173\n",
      "Precision: 0.6650024946762901\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.34      0.47       701\n",
      "         1.0       0.58      0.89      0.70       713\n",
      "\n",
      "    accuracy                           0.62      1414\n",
      "   macro avg       0.67      0.62      0.58      1414\n",
      "weighted avg       0.67      0.62      0.59      1414\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_1.iloc[:, :-1]\n",
    "y = df_1['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "sgd1 = SGDClassifier()\n",
    "sgd1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgd1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8189252336448598\n",
      "F1 score: 0.7374008847592122\n",
      "Recall: 0.8189252336448598\n",
      "Precision: 0.6706385383002883\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      1.00      0.90       701\n",
      "         1.0       0.00      0.00      0.00       155\n",
      "\n",
      "    accuracy                           0.82       856\n",
      "   macro avg       0.41      0.50      0.45       856\n",
      "weighted avg       0.67      0.82      0.74       856\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X = df_2.iloc[:, :-1]\n",
    "y = df_2['Label']\n",
    "\n",
    "#smt = SMOTETomek(sampling_strategy='all')\n",
    "#X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "sgd1 = SGDClassifier()\n",
    "sgd1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgd1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8002336448598131\n",
      "F1 score: 0.7866066606072781\n",
      "Recall: 0.8002336448598131\n",
      "Precision: 0.7776513878939662\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.91      0.88       705\n",
      "         1.0       0.41      0.29      0.34       151\n",
      "\n",
      "    accuracy                           0.80       856\n",
      "   macro avg       0.63      0.60      0.61       856\n",
      "weighted avg       0.78      0.80      0.79       856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_3.iloc[:, :-1]\n",
    "y = df_3['Label']\n",
    "\n",
    "#smt = SMOTETomek(sampling_strategy='all')\n",
    "#X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "sgd1 = SGDClassifier()\n",
    "sgd1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgd1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8364485981308412\n",
      "F1 score: 0.7619557204347103\n",
      "Recall: 0.8364485981308412\n",
      "Precision: 0.6996462573150495\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      1.00      0.91       716\n",
      "         1.0       0.00      0.00      0.00       140\n",
      "\n",
      "    accuracy                           0.84       856\n",
      "   macro avg       0.42      0.50      0.46       856\n",
      "weighted avg       0.70      0.84      0.76       856\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X = df_4.iloc[:, :-1]\n",
    "y = df_4['Label']\n",
    "\n",
    "#smt = SMOTETomek(sampling_strategy='all')\n",
    "#X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "sgd1 = SGDClassifier()\n",
    "sgd1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgd1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8058139534883721\n",
      "F1 score: 0.7315000195774986\n",
      "Recall: 0.8058139534883721\n",
      "Precision: 0.7646235556530642\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.99      0.89       691\n",
      "         1.0       0.58      0.04      0.08       169\n",
      "\n",
      "    accuracy                           0.81       860\n",
      "   macro avg       0.70      0.52      0.48       860\n",
      "weighted avg       0.76      0.81      0.73       860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_5.iloc[:, :-1]\n",
    "y = df_5['Label']\n",
    "\n",
    "#smt = SMOTETomek(sampling_strategy='all')\n",
    "#X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "sgd1 = SGDClassifier()\n",
    "sgd1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgd1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8174418604651162\n",
      "F1 score: 0.735331577616093\n",
      "Recall: 0.8174418604651162\n",
      "Precision: 0.6682111952406706\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      1.00      0.90       703\n",
      "         1.0       0.00      0.00      0.00       157\n",
      "\n",
      "    accuracy                           0.82       860\n",
      "   macro avg       0.41      0.50      0.45       860\n",
      "weighted avg       0.67      0.82      0.74       860\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X = df_6.iloc[:, :-1]\n",
    "y = df_6['Label']\n",
    "\n",
    "#smt = SMOTETomek(sampling_strategy='all')\n",
    "#X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "sgd1 = SGDClassifier()\n",
    "sgd1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgd1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8511627906976744\n",
      "F1 score: 0.7860824036070563\n",
      "Recall: 0.8511627906976744\n",
      "Precision: 0.8733928522970883\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92       729\n",
      "         1.0       1.00      0.02      0.04       131\n",
      "\n",
      "    accuracy                           0.85       860\n",
      "   macro avg       0.93      0.51      0.48       860\n",
      "weighted avg       0.87      0.85      0.79       860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_7.iloc[:, :-1]\n",
    "y = df_7['Label']\n",
    "\n",
    "#smt = SMOTETomek(sampling_strategy='all')\n",
    "#X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "sgd1 = SGDClassifier()\n",
    "sgd1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgd1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8232558139534883\n",
      "F1 score: 0.7434504034171808\n",
      "Recall: 0.8232558139534883\n",
      "Precision: 0.6777501352082207\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      1.00      0.90       708\n",
      "         1.0       0.00      0.00      0.00       152\n",
      "\n",
      "    accuracy                           0.82       860\n",
      "   macro avg       0.41      0.50      0.45       860\n",
      "weighted avg       0.68      0.82      0.74       860\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X = df_8.iloc[:, :-1]\n",
    "y = df_8['Label']\n",
    "\n",
    "#smt = SMOTETomek(sampling_strategy='all')\n",
    "#X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "sgd1 = SGDClassifier()\n",
    "sgd1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgd1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>4. LGBM Classifier</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saloniparekh/opt/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9180212014134276\n",
      "F1 score: 0.9180275935096995\n",
      "Recall: 0.9180212014134276\n",
      "Precision: 0.9180486647135796\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.92      0.92       729\n",
      "         1.0       0.91      0.92      0.92       686\n",
      "\n",
      "    accuracy                           0.92      1415\n",
      "   macro avg       0.92      0.92      0.92      1415\n",
      "weighted avg       0.92      0.92      0.92      1415\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_1.iloc[:, :-1]\n",
    "y = df_1['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "lgb1 = LGBMClassifier(\n",
    "    objective='binary',\n",
    "    boosting='gbdt',\n",
    "    learning_rate = 0.05,\n",
    "    max_depth = 8,\n",
    "    num_leaves = 80,\n",
    "    n_estimators = 400,\n",
    "    bagging_fraction = 0.8,\n",
    "    feature_fraction = 0.9)\n",
    "lgb1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lgb1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9276410998552822\n",
      "F1 score: 0.9276056147159385\n",
      "Recall: 0.9276410998552822\n",
      "Precision: 0.9282280190328265\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.91      0.93       686\n",
      "         1.0       0.91      0.95      0.93       696\n",
      "\n",
      "    accuracy                           0.93      1382\n",
      "   macro avg       0.93      0.93      0.93      1382\n",
      "weighted avg       0.93      0.93      0.93      1382\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_2.iloc[:, :-1]\n",
    "y = df_2['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "lgb1 = LGBMClassifier(\n",
    "    objective='binary',\n",
    "    boosting='gbdt',\n",
    "    learning_rate = 0.05,\n",
    "    max_depth = 8,\n",
    "    num_leaves = 80,\n",
    "    n_estimators = 400,\n",
    "    bagging_fraction = 0.8,\n",
    "    feature_fraction = 0.9)\n",
    "lgb1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lgb1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9340892983699504\n",
      "F1 score: 0.934096052407762\n",
      "Recall: 0.9340892983699504\n",
      "Precision: 0.9343739918851931\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.92      0.93       720\n",
      "         1.0       0.92      0.95      0.93       691\n",
      "\n",
      "    accuracy                           0.93      1411\n",
      "   macro avg       0.93      0.93      0.93      1411\n",
      "weighted avg       0.93      0.93      0.93      1411\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_3.iloc[:, :-1]\n",
    "y = df_3['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "lgb1 = LGBMClassifier(\n",
    "    objective='binary',\n",
    "    boosting='gbdt',\n",
    "    learning_rate = 0.05,\n",
    "    max_depth = 8,\n",
    "    num_leaves = 80,\n",
    "    n_estimators = 400,\n",
    "    bagging_fraction = 0.8,\n",
    "    feature_fraction = 0.9)\n",
    "lgb1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lgb1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9416058394160584\n",
      "F1 score: 0.9415482106453812\n",
      "Recall: 0.9416058394160584\n",
      "Precision: 0.9422806627297597\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94       666\n",
      "         1.0       0.93      0.96      0.94       704\n",
      "\n",
      "    accuracy                           0.94      1370\n",
      "   macro avg       0.94      0.94      0.94      1370\n",
      "weighted avg       0.94      0.94      0.94      1370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_4.iloc[:, :-1]\n",
    "y = df_4['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "lgb1 = LGBMClassifier(\n",
    "    objective='binary',\n",
    "    boosting='gbdt',\n",
    "    learning_rate = 0.05,\n",
    "    max_depth = 8,\n",
    "    num_leaves = 80,\n",
    "    n_estimators = 400,\n",
    "    bagging_fraction = 0.8,\n",
    "    feature_fraction = 0.9)\n",
    "lgb1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lgb1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9207360226468507\n",
      "F1 score: 0.9207419795257026\n",
      "Recall: 0.9207360226468507\n",
      "Precision: 0.9207811442909061\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.92      0.92       722\n",
      "         1.0       0.92      0.92      0.92       691\n",
      "\n",
      "    accuracy                           0.92      1413\n",
      "   macro avg       0.92      0.92      0.92      1413\n",
      "weighted avg       0.92      0.92      0.92      1413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_5.iloc[:, :-1]\n",
    "y = df_5['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "lgb1 = LGBMClassifier(\n",
    "    objective='binary',\n",
    "    boosting='gbdt',\n",
    "    learning_rate = 0.05,\n",
    "    max_depth = 8,\n",
    "    num_leaves = 80,\n",
    "    n_estimators = 400,\n",
    "    bagging_fraction = 0.8,\n",
    "    feature_fraction = 0.9)\n",
    "lgb1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lgb1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9355539464156408\n",
      "F1 score: 0.9355502291428874\n",
      "Recall: 0.9355539464156408\n",
      "Precision: 0.9356652506046376\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.93      0.94       691\n",
      "         1.0       0.93      0.94      0.94       690\n",
      "\n",
      "    accuracy                           0.94      1381\n",
      "   macro avg       0.94      0.94      0.94      1381\n",
      "weighted avg       0.94      0.94      0.94      1381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_6.iloc[:, :-1]\n",
    "y = df_6['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "lgb1 = LGBMClassifier(\n",
    "    objective='binary',\n",
    "    boosting='gbdt',\n",
    "    learning_rate = 0.05,\n",
    "    max_depth = 8,\n",
    "    num_leaves = 80,\n",
    "    n_estimators = 400,\n",
    "    bagging_fraction = 0.8,\n",
    "    feature_fraction = 0.9)\n",
    "lgb1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lgb1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9351656095842142\n",
      "F1 score: 0.9351598131397684\n",
      "Recall: 0.9351656095842142\n",
      "Precision: 0.9352878191451764\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.93      0.93       708\n",
      "         1.0       0.93      0.94      0.94       711\n",
      "\n",
      "    accuracy                           0.94      1419\n",
      "   macro avg       0.94      0.94      0.94      1419\n",
      "weighted avg       0.94      0.94      0.94      1419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_7.iloc[:, :-1]\n",
    "y = df_7['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "lgb1 = LGBMClassifier(\n",
    "    objective='binary',\n",
    "    boosting='gbdt',\n",
    "    learning_rate = 0.05,\n",
    "    max_depth = 8,\n",
    "    num_leaves = 80,\n",
    "    n_estimators = 400,\n",
    "    bagging_fraction = 0.8,\n",
    "    feature_fraction = 0.9)\n",
    "lgb1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lgb1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9327548806941431\n",
      "F1 score: 0.9327105523690288\n",
      "Recall: 0.9327548806941431\n",
      "Precision: 0.9338639908428968\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.91      0.93       691\n",
      "         1.0       0.91      0.96      0.93       692\n",
      "\n",
      "    accuracy                           0.93      1383\n",
      "   macro avg       0.93      0.93      0.93      1383\n",
      "weighted avg       0.93      0.93      0.93      1383\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_8.iloc[:, :-1]\n",
    "y = df_8['Label']\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='all')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smt, y_smt, test_size = 0.2)\n",
    "\n",
    "lgb1 = LGBMClassifier(\n",
    "    objective='binary',\n",
    "    boosting='gbdt',\n",
    "    learning_rate = 0.05,\n",
    "    max_depth = 8,\n",
    "    num_leaves = 80,\n",
    "    n_estimators = 400,\n",
    "    bagging_fraction = 0.8,\n",
    "    feature_fraction = 0.9)\n",
    "lgb1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lgb1.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
